### Predicting Stock Market Indicators Through Twitter “I hope it is not as bad as I fear” ([Link](https://www.sciencedirect.com/science/article/pii/S1877042811023895))

In this paper, Zhang et. al. did analysis on daily twitter data to understand their emotional learning, and used this hope-fear index to correlate with the stock market indicators of Dow Jones, NASDAQ and S&P 500 on the next day, claiming that studying emotional outbursts on Twitter can help predict the direction of stock market hte next day. This paper is significant on a larger, more abstract level, where this made one of the earliest attempts to correlate modern social media data with real-world, tangible effects. This led to opening up the space for more studies in the field of using social media and social data to predict real-world events.  
Of late, we've been discussing the impacts of social computing in real-world events, including politics, activism, online support among others. This is a natural continuation of that discussion. With the large amount of data being generated daily on a multitude of platforms as more and more people get online daily, the natural next step would be "prediction" - trying to correlate this information with something that is yet to happen. Taking a more cynical view and leaning back to the discussion on activism in the previous class, such prediction can also be used to gauge public reaction and upcoming uprisings, and their buildup on public social media. The work also slightly ties back to previous discussions on diffusion of information, significance of tie strength on modern social media, as well as the discussion on the dual role of Twitter today - both as a discussion platform, as well as a news platform.  
Although there had been many different attempts to use social data for prediction, including that for Oscars, box office collections, voter preferences, and some attempts at using sentiment for stock market analysis, this work did novel contributions in utilising randomised, relevant data to apply them towards stock prediction. Stock prediction in itself is a difficult problem, given that such predictions itself can swing the market and nullify the predictions. But subconscious indicators like mood and sentiment can be good proxies to understand the direction of swing of indices, and this paper does it well.  
The study made a few good choices, like using different indices as indicators of both investor fear (VIX) and general trading (the rest). This design choice helps differentiate not just positive and negative sentiment in data, but also the positive and negative sentiment in the parameter being predicted, in this case, stock vs options. Using the follower and retweet count as indicators was a choice about which I feel ambiguous - although it can help understand the snowballing effect and diffusion effects of spreading a certain _mood_ among the investors, this would only be effective if the followers and the author, both are investors or related to investing. That's a major shortcoming which we'll discuss in further paragraphs. Having said that, the correlation seen between the retweet and follower indicators is seen to be small anyway.  
There are two major shortcomings that can be seen with this paper - first being that Twitter data might not be representative for the cause at hand at all. Twitter contains a very diverse demographic, not just with age, but also with nationality, which might contain a lot of non-US users as well. Secondly, the tweets analysed were not specifically looking at information that might be relevant to the markets - like company news, investor discussions, etc. Thus, the general sentiment analysis of random twitter data is not the best choice to build such a prediction model. Using targeted data from Twitter, like targeted with nationality of users or based on topic mentions related to the United States might be more helpful. Similarly, sentiment analysis on tweets that discuss company news, general news that affects markets, or investment discussions might give a much better performance, including that for retweets and followers, since that would garner more relevant people involved.  

---

### Private traits and attributes are predictable from digital records of human behavior ([Link](https://www.pnas.org/doi/pdf/10.1073/pnas.1218772110))

This paper takes a different route compared to the previous one. This focuses more on making predictions about individuals based on their digital footprint - likes/dislikes, demographic profiles and psychometric test results. This topic is significant to study given how much digital footprint we generate each day, and with this data being concentrated with just a few providers, it is very easy for them ot build these inferences about us. Although they claim to use these for "tailored experiences", the data sale market is large too, and hence you being served a wrong deal using your own data is quite possible too (for example insurance companies using wrong inferences to serve you a bad deal).  
This can be tied back to a lot of previous discussions in class, about privacy and identity on social media, a tangential reference to how such inferences can unmask someone's anonymous profile and expose their attributes, a cynical take would also include targeted hate. But a more positive outlook can be the tailored experiences that we see each day online.  
The novelty of this study lies in its simplicity - it takes a very small collection of publicly available data of a person, and tries to run inferences similar to what large corporations do with their private data. It proves that the publicly available digital footprint of a person can also be enough to infer a lot of attributes of the user.  
Some parts of the design are ambiguous in their aim and source, like the question about whether a user's parents stayed with them until age 21. From the outside, there doesn't seem to be any correlation between the data and this parameter, also explaining why the performance on this parameter has been low. Another questionable, or rather unaddressed point was how this data was obtained with user consent. It seems that the data was collected using a Facebook application, but it does not mention whether users were informed how their data was being used. A few of the conclusions also seemed to be more of correlation rather than causal relationships.  
But the study design itself was very robust. The authors relied on good indicators to build their dataset - not just for the Facebook likes and the posts, but also using tests like IPIP and SPM to build a model about the user's personality. Although the efficacy of such tests has been often questioned, these can be good heuristics to model a person.  
