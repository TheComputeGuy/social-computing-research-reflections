### Tweeting is Believing? Understanding Microblog Credibility Perceptions ([link](https://dl.acm.org/doi/pdf/10.1145/2145204.2145274))

In Tweeting is Believing, Morris et al. present an investigation of user perceptions of tweet credibility, where they discovered that there is a discrepancy in the features that users deem to be indicators of credible information, and the features made available by search engines. The authors also discuss strategies that tweet authors can use to enhance their credibility with users, and manipulative strategies which users should be wary of. Lastly, a few ideas are offered to improve social media search pages. This is an important topic to study, given the proliferation of social media as a news platform today, and the sway that social media trends have over users. It is also an important focus study given the influence of social media misinformation and disinformation seen on democratic events like elections and riots.  
The authors conducted a survey to first understand user behavior when searching for tweets. The survey participant design was reasonable, with a diverse demographic and various background being represented in the study. This ensures that the study covers opinions from people across age groups, literacy levels, familiarity with the platform, and a general variation in the way they think based on their backgrounds.  
One area I felt that the authors did not touch upon was ethics - the tweet manipulation experiment included using photographs of real Twitter users, for which it is not mentioned whether their consent was obtained. Having said that, if the experiment was conducted today, it would be trivially easy to create realistic-looking photographs of non-existent people using AI (tools like [This person does not exist](https://this-person-does-not-exist.com/en) already do it.)  
Also, the authors mention that during the experiments, the participants' credibility judgement was mostly influenced by factors other than truthfulness. But that sounds like a logical fallacy, since the participants were not allowed to validate the truthfulness of the tweets in the first place, causing them to base their judgement on other factors. Hence, blaming them to not consider the actual truthfulness of the tweet sounds like a self-serving observation.  
It'd also be interesting to see how factors like race and religion (signalled via user image or name) affect people's opinions, especially on divisive topics like politics, in regions and populations of the world where these differentiating factors are widely seen.  
Going back to the classroom, and this is tangentially related, but there are aspects of "social translucence" in the HCI study under question. People made use of various cues in terms of author reputation and topic reputation when making judgement about credibility of a certain tweet, and thus, tangentially related to the idea of social translucence.  
One of the features mentioned in the survey by participants, as an indicator of credibility, was the "official Twitter verification seal", as is expected. But with the recent announcements by Twitter and Facebook's parent Meta about having a paid-for verification system, anyone with $8 in their account can get the verification seal, which has been used as a proxy for credibility over the years by the users. With such defenses falling to corporate whims, it'll be interesting to see what new factors emerge as proxies for user account credibility.  

---

### Understanding Anti-Vaccination Attitudes in Social Media ([link](https://people.cs.vt.edu/tmitra/public/papers/Anti-Vax-attitudes-twitter.pdf))

In this paper, Mitra et al. explore the world of anti-vax on Twitter, trying to understand both long-term and new adopters of the anti-vaccination stance, their social media behaviors, and comparing and contrasting that with the behaviors of users with a pro-vaccine stance. The paper uses great methodologies to analyse social media data, and does a great job at researching the language and characteristics of various cohorts. The topic holds great significance in today's times, both specifically in terms of anti-vaccine and conspiracy theories taking hold on social media (especially after the pandemic), and in general, the study about misinformation and people spreading misinformation online.  
The paper makes great use of the Meaning Extraction Method to understand "what" topics people in different cohorts talk about, and how it is mapped to their general ideologies and patterns seen in the cohorts. The study was well prepared, looking at various aspects like themes of conversation, and change in interests over time, emotion, lingusitic styles, areas of concern, etc. The study of joiners was even more interesting, trying to understand their personality/social media characteristics, and what drives their decision to join the anti-vaccine cohort. I feel the methodologies were very useful given that the authors aimed to study the motivation and behaviors of anti-vaccine users on Twitter,and both MEM as well as LIWC methods were apt for the goal.  
Although the authors mention a few limitations of their study, I feel they have done a great job given that their problem statement was restrictive - studying Twitter users with anti-vaccination attitudes. The only gap I feel their study has, is that their search terms are very specific. They can do a general empirical search of Twitter to identify more robust and more general anti-vaccine search terms, which might not necessarily have a large false positive rate. Secondly, it'll be interesting to study social media like Reddit and Facebook groups, where conspiracy theory echo chambers can foster easily.  
I feel that this paper was a great demonstration of what kind of analyses can be made on social media, especially when studying and comparing cohorts. The linguistic study and research question design are good examples of of what we can explore as a part of our projects as well.  