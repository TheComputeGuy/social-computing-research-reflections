### Examining the Alternative Media Ecosystem through the Production of Alternative Narratives of Mass Shooting Events on Twitter ([link](https://faculty.washington.edu/kstarbi/Alt_Narratives_ICWSM17-CameraReady.pdf))

In this paper, Starbird studies "alternative media" - platforms that host _alternative narratives_ of popular events, or conspiracy theories, and how it contributes to conspirational thinking. With time, over the past few years, the "fake news" narrative has been taking hold of social media discourse, and is regularly used to discredit opposing viewpoints. It has been used by many influential actors, and thus, it has become an important topic to study - how can someone classify misinformation, how it spreads, and how it influences narratives, given the large impact that the scale of social media has on users. Not to mention, this research itself was inspired by a few such events.  
In recent classes, we've been studying topics like credibility of information online, heuristics used by people to determine credible information, etc. One recurrent discussion theme in this has been that it is difficult to convert someone's biased opinion, however credible the information source might be, building echo chambers. This study goes further down the path of how people build narratives, and what does the whole interconnected ecosystem look like, where does it all start and why.  
The paper takes an interesting approach to study alternative narratives - by studying the interconnected nature of interactions on social media, utilising alternative media. It builds a map of domains that are often cited along with alternative narratives, sans a few rules to clean low connected nodes. I felt that the study design was a good proxy to understand misinformation - tweets alone cannot give you insights about the "why" of misinformation, while looking at the source of misinformation adds a new aspect to our understanding of their motivations. Looking at the graph also helps correlate and potentially find sources that might be run by the same operators, looking at a large-scale misinformation campaign.  
Having said that, whenever research on such topics comes up, a big concern is the presence of automated or bot accounts, that can be easily programmed to inflate the importance of a certain hashtag or narrative. The author mentioned that for the ~90000 tweets studied, the number of unique users was just around 1300, which points to some bot activity driving the popularity of alternative narratives. Although tangential, an alternative way to study misinformation would be studying echo chamber communities on platforms like Reddit and Facebook groups, where the chance of finding humans is higher, as well as the conversations might have much more content to be analysed. But in that case, the study might not be able to focus on "alternative media" houses.  

---

### The spread of true and false news online ([link](https://www.science.org/doi/10.1126/science.aap9559))

They say that "A lie can travel halfway round the world while the truth is putting on its shoes". This paper tries to put this quote into context with respect to disinformation on social media. Along with studying the diffusion of false news itself, the paper also looks at other aspects of false news - like it being "novel information", emotions evoked, and the impact of bots on the aforementioned diffusion.  
The study design was interesting, especially the virality metric, since that differentiated posts that did better because of a peer-to-peer interaction rather than just simple broadcast (potentially indicative of bot activity). The novelty metric was interesting too, especially because it gave a new spin to the content rather than just true-vs-false. It helped expose a small, third possibility, that people might be sharing _novel_ information rather than sharing true or false news, a neutral stance compared to sharing false news with propaganda behind it. The emotional analysis is another interesting angle added, that aims to show the user's perception of novelty rather than just a statistical inference of novelty. The study was backed by solid, statistical metrics rather than heuristic inferences, and thus, leads to more believable results.  
One area in which this study can be further enhanced is understanding cohorts - whether there are certain groups of users which are seen to be spreading disinformation more, every time a new post by a more influential account goes up. This could help understand and categorize users into various groups, also to identify users that are chronic disinformation spreaders.  
Disinformation online has been growing for years now, and one bit of false news online can easily destroy someone's life. This gives all the more incentive for us to work on this problem and make internet a better place.  